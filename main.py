#!/usr/bin/env python3
"""
Main script for PDF processing workflow.

This script orchestrates the complete PDF processing workflow:
1. Process PDFs from data/input/ directories
2. Generate JSON files according to the schema from prompt.md
3. Save results to data/output/
4. Provide comprehensive logging and progress reporting

Usage:
    python main.py --section 3.1           # Process specific section
    python main.py --all                   # Process all sections
    python main.py --file path/to/file.pdf # Process single file
"""

import argparse
import sys
import os
import json
from pathlib import Path
from dotenv import load_dotenv
from pdf_processor import PDFProcessor

# Load environment variables from .env file
load_dotenv()

# API key from environment variable
API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    print("‚ùå Error: GEMINI_API_KEY environment variable not set!")
    print("üí° Options to fix this:")
    print("   1. Set environment variable: export GEMINI_API_KEY='your-api-key-here'")
    print("   2. Create .env file: cp .env.example .env and edit it")
    print("   3. Get API key from: https://aistudio.google.com/app/apikey")
    sys.exit(1)

# Section descriptions from prompt.md
SECTION_DESCRIPTIONS = {
    "2.3": "–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ —Å–∏–º—É–ª—è—Ü–∏–π —Ä–∞–±–æ—Ç—ã –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö.",
    "2.4": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–∏–º—É–ª—è—Ü–∏–π.",
    "2.5": "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ –±–µ—Ä–µ–∂–ª–∏–≤–æ–≥–æ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞.",
    "3.1": "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ —Å–∏—Å—Ç–µ–º–µ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.",
    "3.2": "–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –¥–∞—Ç—á–∏–∫–æ–≤ –∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤ IIoT.",
    "3.3": "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.",
    "4.1": "–°–±–æ—Ä –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö.",
    "4.2": "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.",
    "4.3": "–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π, —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤.",
    "4.4": "–ê–Ω–∞–ª–∏–∑ –∏ –≤—ã—è–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π.",
    "4.5": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –±—É–¥—É—â–∏—Ö —Å–æ–±—ã—Ç–∏–π.",
    "5.1": "–ê–Ω–∞–ª–∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–∏—Å—Ç–µ–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è.",
    "5.2": "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è 3D –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤.",
    "5.3": "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.",
    "5.4": "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∫–∏–±–µ—Ä—Ñ–∏–∑–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ.",
    "6.1": "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É.",
    "6.2": "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ—Ç–æ—Ç–∏–ø–æ–≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.",
    "6.3": "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞.",
    "6.4": "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–ª–∞–¥–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.",
    "6.5": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."
}

def find_available_sections():
    """Find all available section directories."""
    input_dir = Path("data/input")
    if not input_dir.exists():
        return []

    sections = []
    for item in input_dir.iterdir():
        if item.is_dir() and item.name in SECTION_DESCRIPTIONS:
            # Check if directory has PDF files
            pdf_files = list(item.glob("*.pdf"))
            if pdf_files:
                sections.append((item.name, len(pdf_files)))

    return sorted(sections)

def process_section(processor, section_code, use_resume=False, start_from=1, resume_method="smart", parallel=False, workers=3):
    """Process all PDFs in a specific section."""
    directory_path = f"data/input/{section_code}"

    if not Path(directory_path).exists():
        print(f"‚ùå Section directory not found: {directory_path}")
        return False

    print(f"\nüîÑ Processing Section {section_code}: {SECTION_DESCRIPTIONS.get(section_code, 'Unknown section')}")
    print(f"üìÅ Directory: {directory_path}")

    if parallel:
        print(f"üöÄ Using PARALLEL processing with {workers} workers")
        print(f"‚ö° This will be MUCH faster!")
    elif use_resume:
        print(f"üîÑ Using {resume_method} resume functionality")
        if start_from > 1:
            print(f"üìç Starting from sequence {start_from}")

    # Process the directory
    if parallel:
        # Parallel processing (fastest)
        results = processor.process_pdfs_parallel(directory_path, section_code, workers)
    elif use_resume:
        # Resume processing
        if resume_method == "simple":
            results = processor.process_pdfs_in_directory_with_resume(directory_path, section_code, start_from)
        else:  # smart method
            results = processor.process_pdfs_with_resume(directory_path, section_code, start_from)
    else:
        # Sequential processing
        results = processor.process_pdfs_in_directory(directory_path, section_code)

    if results["success"]:
        print(f"\n‚úÖ Section {section_code} completed successfully!")
        print(f"üìä Processed: {results['processed']}/{results['total_files']} files")
        if results['failed'] > 0:
            print(f"‚ö†Ô∏è  Failed: {results['failed']} files")
        if results.get('skipped', 0) > 0:
            print(f"‚è≠Ô∏è  Skipped: {results['skipped']} files")
        if results.get('parallel_workers'):
            print(f"üöÄ Used {results['parallel_workers']} parallel workers")
    else:
        print(f"\n‚ùå Section {section_code} failed: {results.get('error', 'Unknown error')}")
        return False

    return True

def process_single_file(processor, file_path, section_code=None, sequence_id=None):
    """Process a single PDF file."""
    file_path = Path(file_path)

    if not file_path.exists():
        print(f"‚ùå File not found: {file_path}")
        return False

    if not file_path.suffix.lower() == '.pdf':
        print(f"‚ùå Not a PDF file: {file_path}")
        return False

    # Auto-detect section if not provided
    if section_code is None:
        # Try to extract from path (e.g., data/input/3.1/file.pdf)
        path_parts = file_path.parts
        for part in path_parts:
            if part in SECTION_DESCRIPTIONS:
                section_code = part
                break

        if section_code is None:
            section_code = "misc"  # Default section

    # Auto-detect sequence ID if not provided
    if sequence_id is None:
        sequence_id = 1

    print(f"\nüîÑ Processing single file:")
    print(f"üìÑ File: {file_path}")
    print(f"üè∑Ô∏è  Section: {section_code}")
    print(f"üî¢ Sequence: {sequence_id}")

    success = processor.process_single_pdf(str(file_path), section_code, sequence_id)

    if success:
        paper_id = f"{section_code}-{sequence_id:03d}"
        print(f"‚úÖ File processed successfully!")
        print(f"üìã Output: data/output/{section_code}/{paper_id}.json")
    else:
        print(f"‚ùå File processing failed")
        return False

    return True

def main():
    parser = argparse.ArgumentParser(
        description="Process PDF papers to generate structured JSON data",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python main.py --list                                 # List available sections
    python main.py --list-files 3.1                      # List files in section 3.1 with numbers and status
    python main.py --section 3.1 --parallel              # Process section 3.1 in PARALLEL (3x faster!)
    python main.py --section 3.1 --parallel --workers 5  # Use 5 parallel workers (max speed)
    python main.py --section 3.1 --use-resume           # Process section 3.1 with smart resume (skip already processed)
    python main.py --resume 3.1 --start-from 26         # Resume section 3.1 from sequence 26
    python main.py --all --parallel                     # Process all sections in parallel (fastest)
    python main.py --file paper.pdf                     # Process a single PDF file
        """
    )

    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--section", type=str, help="Process specific section (e.g., 3.1)")
    group.add_argument("--all", action="store_true", help="Process all available sections")
    group.add_argument("--file", type=str, help="Process single PDF file")
    group.add_argument("--list", action="store_true", help="List available sections")
    group.add_argument("--list-files", type=str, help="List files in a specific section with numbers")
    group.add_argument("--resume", type=str, help="Resume processing from a specific section")

    parser.add_argument("--sequence-id", type=int, help="Sequence ID for single file processing")
    parser.add_argument("--start-from", type=int, help="Start processing from specific sequence number (for resume)")
    parser.add_argument("--use-resume", action="store_true", help="Use smart resume functionality that skips already processed files")
    parser.add_argument("--resume-method", choices=["smart", "simple"], default="smart", help="Resume method: 'smart' (sequence-based) or 'simple' (filename-based)")
    parser.add_argument("--parallel", action="store_true", help="Use parallel processing for faster execution")
    parser.add_argument("--workers", type=int, default=3, help="Number of parallel workers (default: 3, max recommended: 5)")

    args = parser.parse_args()

    # List available sections
    if args.list:
        available_sections = find_available_sections()

        if not available_sections:
            print("‚ùå No sections with PDF files found in data/input/")
            return 1

        print("üìã Available sections:")
        for section, count in available_sections:
            description = SECTION_DESCRIPTIONS.get(section, "Unknown section")
            print(f"   {section}: {description} ({count} PDFs)")

        return 0

    # List files in specific section
    if args.list_files:
        if args.list_files not in SECTION_DESCRIPTIONS:
            print(f"‚ùå Unknown section: {args.list_files}")
            print(f"Available sections: {', '.join(SECTION_DESCRIPTIONS.keys())}")
            return 1

        directory_path = f"data/input/{args.list_files}"
        directory = Path(directory_path)

        if not directory.exists():
            print(f"‚ùå Section directory not found: {directory_path}")
            return 1

        pdf_files = sorted(list(directory.glob("*.pdf")), key=lambda x: x.name.lower())

        if not pdf_files:
            print(f"‚ùå No PDF files found in section {args.list_files}")
            return 1

        print(f"üìã Files in section {args.list_files}:")
        print(f"üìÅ Directory: {directory_path}")
        print(f"üî¢ Total files: {len(pdf_files)}")
        print()

        for idx, pdf_file in enumerate(pdf_files, 1):
            paper_id = f"{args.list_files}-{idx:03d}"

            # Check if already processed
            output_file = Path(f"data/output/{args.list_files}/{paper_id}.json")
            status = "‚úÖ Processed" if output_file.exists() else "‚è≥ Pending"

            print(f"  {idx:2d}. {pdf_file.name}")
            print(f"      üìã Paper ID: {paper_id}")
            print(f"      üìä Status: {status}")
            print()

        return 0

    # Initialize processor
    print("üöÄ Initializing PDF processor...")
    try:
        processor = PDFProcessor(API_KEY)
        print("‚úÖ PDF processor initialized successfully")
    except Exception as e:
        print(f"‚ùå Failed to initialize PDF processor: {str(e)}")
        return 1

    success = True

    # Process single file
    if args.file:
        success = process_single_file(processor, args.file, sequence_id=args.sequence_id)

    # Process specific section
    elif args.section:
        if args.section not in SECTION_DESCRIPTIONS:
            print(f"‚ùå Unknown section: {args.section}")
            print(f"Available sections: {', '.join(SECTION_DESCRIPTIONS.keys())}")
            return 1

        start_from = args.start_from or 1
        success = process_section(processor, args.section, args.use_resume, start_from, args.resume_method, args.parallel, args.workers)

    # Resume processing from a specific section
    elif args.resume:
        if args.resume not in SECTION_DESCRIPTIONS:
            print(f"‚ùå Unknown section: {args.resume}")
            print(f"Available sections: {', '.join(SECTION_DESCRIPTIONS.keys())}")
            return 1

        start_from = args.start_from or 1
        print(f"üîÑ Resuming processing for section {args.resume}")
        success = process_section(processor, args.resume, True, start_from, args.resume_method, args.parallel, args.workers)

    # Process all sections
    elif args.all:
        available_sections = find_available_sections()

        if not available_sections:
            print("‚ùå No sections with PDF files found in data/input/")
            return 1

        print(f"üîÑ Processing {len(available_sections)} sections...")

        all_success = True
        for section, count in available_sections:
            section_success = process_section(processor, section, args.use_resume, 1, args.resume_method, args.parallel, args.workers)
            if not section_success:
                all_success = False

        success = all_success

        if success:
            print("\nüéâ All sections processed successfully!")
        else:
            print("\n‚ö†Ô∏è  Some sections failed to process completely")

    if success:
        print("\n‚úÖ Processing completed successfully!")
        return 0
    else:
        print("\n‚ùå Processing failed")
        return 1

if __name__ == "__main__":
    sys.exit(main())